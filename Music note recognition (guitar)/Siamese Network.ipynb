{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Music Note sounds using Few Shot Deep Learning\n",
    "\n",
    "credit: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Preprocessed data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction refinement \n",
    "\n",
    "In the prevous feature extraction stage, the MFCC vectors would vary in size for the different audio files (depending on the samples duration). \n",
    "\n",
    "However, CNNs require a fixed size for all inputs. To overcome this we will zero pad the output vectors to make them all the same size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_pad_len = 365\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name, e)\n",
    "        return None \n",
    "     \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  58  files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "DATA_DIR = os.path.join(\"data\", \"guitar_sample\")\n",
    "\n",
    "# feature list\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for folder in os.listdir(DATA_DIR):\n",
    "    for file in os.listdir(os.path.join(DATA_DIR, folder)):\n",
    "        class_label = folder\n",
    "        file_name = os.path.join(os.path.join(DATA_DIR, folder, file))\n",
    "        \n",
    "        data = extract_features(file_name)\n",
    "        features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def prepare_train_pair(X, y, label):\n",
    "    indices = np.array(list(range(len(y))))\n",
    "    \n",
    "    similar_indices = indices[y == label]\n",
    "    dissimilar_indices = indices[y != label]\n",
    "    \n",
    "    np.random.shuffle(dissimilar_indices)\n",
    "    \n",
    "    similar_indices_pair = []\n",
    "    dissimilar_indices_pair = []\n",
    "    \n",
    "    it = iter(dissimilar_indices)\n",
    "    size = 0\n",
    "    \n",
    "    for i, j in combinations(similar_indices, 2):\n",
    "        size += 1\n",
    "        similar_indices_pair.append([i, j])\n",
    "        dissimilar_indices_pair.append([i, next(it)])\n",
    "    \n",
    "    # get the dimension of data based on combination\n",
    "    dim = tuple([2, 2*size] + list(X.shape[1:]))\n",
    "    \n",
    "    # build the sim and dis-sim matrix\n",
    "    new_X = np.empty(dim, dtype=float)\n",
    "    new_y = np.concatenate([np.ones(size, dtype=float), np.zeros(size, dtype=float)])\n",
    "    \n",
    "    similar_indices_pair = np.array(similar_indices_pair)\n",
    "    dissimilar_indices_pair = np.array(dissimilar_indices_pair)\n",
    "    \n",
    "    new_X[0, :size], new_X[1, :size] = X[similar_indices_pair[:, 0]], X[similar_indices_pair[:, 1]]\n",
    "    new_X[0:, size:], new_X[1, size:] = X[dissimilar_indices_pair[:, 0]], X[dissimilar_indices_pair[:, 1]]\n",
    "    \n",
    "    all_indices = np.array(list(range(2*size)))\n",
    "    np.random.shuffle(all_indices)\n",
    "    \n",
    "    return new_X[:, all_indices], new_y[all_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# prepare data set pairs (similar and dissimilar)\n",
    "X, y = prepare_train_pair(X, y, \"G\")\n",
    "\n",
    "n, datasize, num_rows, num_columns = X.shape\n",
    "\n",
    "# reshape for training\n",
    "X = X.reshape(n, datasize, num_rows, num_columns, 1)\n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train_indices, x_test_indices, y_train, y_test = train_test_split(np.array(list(range(datasize))), y, test_size=0.2, random_state = 42)\n",
    "x_train, x_test = X[:, x_train_indices], X[:, x_test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 72, 40, 365, 1), (72,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 57, 40, 365, 1), (2, 15, 40, 365, 1), (57,), (15,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network (CNN) model architecture \n",
    "\n",
    "\n",
    "We will modify our model to be a Convolutional Neural Network (CNN) again using Keras and a Tensorflow backend. \n",
    "\n",
    "Again we will use a `sequential` model, starting with a simple model architecture, consisting of four `Conv2D` convolution layers, with our final output layer being a `dense` layer. \n",
    "\n",
    "The convolution layers are designed for feature detection. It works by sliding a filter window over the input and performing a matrix multiplication and storing the result in a feature map. This operation is known as a convolution. \n",
    "\n",
    "\n",
    "The `filter` parameter specifies the number of nodes in each layer. Each layer will increase in size from 16, 32, 64 to 128, while the `kernel_size` parameter specifies the size of the kernel window which in this case is 2 resulting in a 2x2 filter matrix. \n",
    "\n",
    "The first layer will receive the input shape of (40, 174, 1) where 40 is the number of MFCC's 174 is the number of frames taking padding into account and the 1 signifying that the audio is mono. \n",
    "\n",
    "The activation function we will be using for our convolutional layers is `ReLU` which is the same as our previous model. We will use a smaller `Dropout` value of 20% on our convolutional layers. \n",
    "\n",
    "Each convolutional layer has an associated pooling layer of `MaxPooling2D` type with the final convolutional layer having a `GlobalAveragePooling2D` type. The pooling layer is do reduce the dimensionality of the model (by reducing the parameters and subsquent computation requirements) which serves to shorten the training time and reduce overfitting. The Max Pooling type takes the maximum size for each window and the Global Average Pooling type takes the average which is suitable for feeding into our `dense` output layer.  \n",
    "\n",
    "Our output layer will have 10 nodes (num_labels) which matches the number of possible classifications. The activation is for our output layer is `softmax`. Softmax makes the output sum up to 1 so the output can be interpreted as probabilities. The model will then make its prediction based on which option has the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Lambda, GlobalAveragePooling2D\n",
    "\n",
    "def build_base_network2(input_shape):\n",
    "    filter_size = 2\n",
    "\n",
    "    # Construct model \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=2, input_shape=input_shape, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256))\n",
    "    \n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(128))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def build_base_network(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    return model\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def distance(emb1, emb2):\n",
    "    return np.sum(np.square(emb1 - emb2))\n",
    "\n",
    "\n",
    "def predict(afs, y, threshold=0.5):\n",
    "    print(afs.shape)\n",
    "    acc = 0\n",
    "    preds = model.predict([afs[0], afs[1]])\n",
    "    for i in range(len(preds)):\n",
    "        p = preds[i][0]\n",
    "        z = int(p < threshold)\n",
    "        if z == y[i]:\n",
    "            acc += 1\n",
    "        print(z, y[i], p)\n",
    "    print('acc = {}%'.format(acc*100/len(preds)))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model \n",
    "\n",
    "For compiling our model, we will use the same three parameters as the previous model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[2:]\n",
    "\n",
    "audio_a = Input(shape=input_dim)\n",
    "audio_b = Input(shape=input_dim)\n",
    "\n",
    "base_network = build_base_network(input_dim)\n",
    "\n",
    "feat_vecs_a = base_network(audio_a)\n",
    "feat_vecs_b = base_network(audio_b)\n",
    "\n",
    "difference = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])\n",
    "\n",
    "# initialize training params\n",
    "epochs = 64\n",
    "batch_size = 24\n",
    "optimizer = Adam() #RMSprop()\n",
    "\n",
    "# initialize the network\n",
    "model = Model(inputs=[audio_a, audio_b], outputs=difference)\n",
    "model.compile(loss=contrastive_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40, 365, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 40, 365, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 128)          20509472    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[0][0]                 \n",
      "                                                                 sequential[1][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,509,472\n",
      "Trainable params: 20,509,472\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 57, 40, 365, 1)\n",
      "0 0.0 16.871254\n",
      "0 1.0 5.0769644\n",
      "0 0.0 15.167051\n",
      "0 0.0 17.08545\n",
      "0 0.0 18.611961\n",
      "0 0.0 16.556719\n",
      "0 1.0 6.293456\n",
      "0 0.0 17.742388\n",
      "0 0.0 16.729364\n",
      "0 1.0 14.330191\n",
      "0 1.0 14.707417\n",
      "0 1.0 31.302975\n",
      "0 1.0 28.512344\n",
      "0 1.0 13.650093\n",
      "0 0.0 16.04457\n",
      "0 1.0 7.4985375\n",
      "0 0.0 16.458845\n",
      "0 1.0 5.940324\n",
      "0 0.0 17.554096\n",
      "0 1.0 31.205189\n",
      "0 1.0 6.166374\n",
      "0 1.0 5.940142\n",
      "0 1.0 14.611991\n",
      "0 0.0 17.171213\n",
      "0 1.0 7.0209956\n",
      "0 0.0 19.273155\n",
      "0 0.0 15.485283\n",
      "0 1.0 32.113766\n",
      "0 1.0 6.4819913\n",
      "0 0.0 41.84114\n",
      "0 0.0 17.051504\n",
      "0 1.0 31.418772\n",
      "0 1.0 31.099882\n",
      "0 1.0 30.089296\n",
      "0 0.0 17.512714\n",
      "0 0.0 17.983402\n",
      "0 1.0 4.478962\n",
      "0 0.0 15.453634\n",
      "0 1.0 3.98404\n",
      "0 0.0 18.87347\n",
      "0 0.0 15.574558\n",
      "0 1.0 15.25096\n",
      "0 0.0 17.033222\n",
      "0 1.0 9.094498\n",
      "0 1.0 6.2206836\n",
      "0 0.0 16.283693\n",
      "0 1.0 14.579174\n",
      "0 0.0 15.614336\n",
      "0 0.0 16.355484\n",
      "0 0.0 19.669628\n",
      "0 1.0 6.331181\n",
      "0 1.0 4.206341\n",
      "0 0.0 18.323875\n",
      "0 1.0 5.301945\n",
      "0 0.0 17.164194\n",
      "0 0.0 18.651783\n",
      "0 1.0 4.5669675\n",
      "acc = 49.12280701754386%\n"
     ]
    }
   ],
   "source": [
    "predict(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 15, 40, 365, 1)\n",
      "0 1.0 2.9108527\n",
      "0 1.0 30.424143\n",
      "0 0.0 25.027956\n",
      "0 1.0 4.3869987\n",
      "0 0.0 16.149446\n",
      "0 0.0 16.139362\n",
      "0 0.0 15.685213\n",
      "0 1.0 5.8893046\n",
      "0 0.0 14.78619\n",
      "0 0.0 26.74393\n",
      "0 1.0 8.817082\n",
      "0 1.0 6.2021866\n",
      "0 0.0 22.398136\n",
      "0 0.0 16.2329\n",
      "0 1.0 16.078587\n",
      "acc = 53.333333333333336%\n"
     ]
    }
   ],
   "source": [
    "predict(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "Here we will train the model. As training a CNN can take a sigificant amount of time, we will start with a low number of epochs and a low batch size. If we can see from the output that the model is converging, we will increase both numbers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 4070.9509\n",
      "Epoch 00001: val_loss improved from inf to 101.66930, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 1s/step - loss: 4070.9509 - val_loss: 101.6693\n",
      "Epoch 2/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 1787.3005\n",
      "Epoch 00002: val_loss improved from 101.66930 to 35.64974, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 897ms/step - loss: 1787.3005 - val_loss: 35.6497\n",
      "Epoch 3/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 447.5334\n",
      "Epoch 00003: val_loss improved from 35.64974 to 10.92859, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 1s/step - loss: 447.5334 - val_loss: 10.9286\n",
      "Epoch 4/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 146.6012\n",
      "Epoch 00004: val_loss improved from 10.92859 to 4.82101, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 891ms/step - loss: 146.6012 - val_loss: 4.8210\n",
      "Epoch 5/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 46.5857\n",
      "Epoch 00005: val_loss improved from 4.82101 to 2.57766, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 883ms/step - loss: 46.5857 - val_loss: 2.5777\n",
      "Epoch 6/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 19.0745\n",
      "Epoch 00006: val_loss improved from 2.57766 to 1.55828, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 861ms/step - loss: 19.0745 - val_loss: 1.5583\n",
      "Epoch 7/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.3926\n",
      "Epoch 00007: val_loss improved from 1.55828 to 1.18983, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 884ms/step - loss: 11.3926 - val_loss: 1.1898\n",
      "Epoch 8/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 7.0165\n",
      "Epoch 00008: val_loss improved from 1.18983 to 0.96244, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 7.0165 - val_loss: 0.9624\n",
      "Epoch 9/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 5.6161\n",
      "Epoch 00009: val_loss improved from 0.96244 to 0.65063, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 902ms/step - loss: 5.6161 - val_loss: 0.6506\n",
      "Epoch 10/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.8275\n",
      "Epoch 00010: val_loss improved from 0.65063 to 0.42140, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 872ms/step - loss: 3.8275 - val_loss: 0.4214\n",
      "Epoch 11/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.4655\n",
      "Epoch 00011: val_loss improved from 0.42140 to 0.34388, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 892ms/step - loss: 2.4655 - val_loss: 0.3439\n",
      "Epoch 12/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3711\n",
      "Epoch 00012: val_loss improved from 0.34388 to 0.28961, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3711 - val_loss: 0.2896\n",
      "Epoch 13/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8808\n",
      "Epoch 00013: val_loss improved from 0.28961 to 0.24337, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 841ms/step - loss: 0.8808 - val_loss: 0.2434\n",
      "Epoch 14/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6482\n",
      "Epoch 00014: val_loss improved from 0.24337 to 0.20629, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 960ms/step - loss: 0.6482 - val_loss: 0.2063\n",
      "Epoch 15/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4603\n",
      "Epoch 00015: val_loss improved from 0.20629 to 0.16665, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 851ms/step - loss: 0.4603 - val_loss: 0.1667\n",
      "Epoch 16/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3148\n",
      "Epoch 00016: val_loss improved from 0.16665 to 0.14007, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 862ms/step - loss: 0.3148 - val_loss: 0.1401\n",
      "Epoch 17/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2839\n",
      "Epoch 00017: val_loss improved from 0.14007 to 0.12023, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 854ms/step - loss: 0.2839 - val_loss: 0.1202\n",
      "Epoch 18/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2430\n",
      "Epoch 00018: val_loss improved from 0.12023 to 0.10535, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 841ms/step - loss: 0.2430 - val_loss: 0.1054\n",
      "Epoch 19/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1944\n",
      "Epoch 00019: val_loss improved from 0.10535 to 0.09133, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 846ms/step - loss: 0.1944 - val_loss: 0.0913\n",
      "Epoch 20/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1819\n",
      "Epoch 00020: val_loss improved from 0.09133 to 0.07829, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 998ms/step - loss: 0.1819 - val_loss: 0.0783\n",
      "Epoch 21/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1576\n",
      "Epoch 00021: val_loss improved from 0.07829 to 0.06881, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 835ms/step - loss: 0.1576 - val_loss: 0.0688\n",
      "Epoch 22/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1364\n",
      "Epoch 00022: val_loss improved from 0.06881 to 0.06189, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 837ms/step - loss: 0.1364 - val_loss: 0.0619\n",
      "Epoch 23/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1287\n",
      "Epoch 00023: val_loss improved from 0.06189 to 0.05461, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 862ms/step - loss: 0.1287 - val_loss: 0.0546\n",
      "Epoch 24/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1106\n",
      "Epoch 00024: val_loss improved from 0.05461 to 0.04767, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 848ms/step - loss: 0.1106 - val_loss: 0.0477\n",
      "Epoch 25/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1008\n",
      "Epoch 00025: val_loss improved from 0.04767 to 0.04071, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 851ms/step - loss: 0.1008 - val_loss: 0.0407\n",
      "Epoch 26/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0924\n",
      "Epoch 00026: val_loss improved from 0.04071 to 0.03684, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 846ms/step - loss: 0.0924 - val_loss: 0.0368\n",
      "Epoch 27/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0938\n",
      "Epoch 00027: val_loss improved from 0.03684 to 0.03614, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 851ms/step - loss: 0.0938 - val_loss: 0.0361\n",
      "Epoch 28/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0840\n",
      "Epoch 00028: val_loss improved from 0.03614 to 0.03612, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 897ms/step - loss: 0.0840 - val_loss: 0.0361\n",
      "Epoch 29/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0784\n",
      "Epoch 00029: val_loss improved from 0.03612 to 0.03428, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 937ms/step - loss: 0.0784 - val_loss: 0.0343\n",
      "Epoch 30/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0733\n",
      "Epoch 00030: val_loss improved from 0.03428 to 0.03131, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 847ms/step - loss: 0.0733 - val_loss: 0.0313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0711\n",
      "Epoch 00031: val_loss improved from 0.03131 to 0.02643, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 849ms/step - loss: 0.0711 - val_loss: 0.0264\n",
      "Epoch 32/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0657\n",
      "Epoch 00032: val_loss improved from 0.02643 to 0.02384, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 850ms/step - loss: 0.0657 - val_loss: 0.0238\n",
      "Epoch 33/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0620\n",
      "Epoch 00033: val_loss improved from 0.02384 to 0.02274, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 835ms/step - loss: 0.0620 - val_loss: 0.0227\n",
      "Epoch 34/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0593\n",
      "Epoch 00034: val_loss improved from 0.02274 to 0.02265, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 835ms/step - loss: 0.0593 - val_loss: 0.0227\n",
      "Epoch 35/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0557\n",
      "Epoch 00035: val_loss improved from 0.02265 to 0.02264, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 845ms/step - loss: 0.0557 - val_loss: 0.0226\n",
      "Epoch 36/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0542\n",
      "Epoch 00036: val_loss improved from 0.02264 to 0.02023, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 855ms/step - loss: 0.0542 - val_loss: 0.0202\n",
      "Epoch 37/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0525\n",
      "Epoch 00037: val_loss improved from 0.02023 to 0.01845, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 951ms/step - loss: 0.0525 - val_loss: 0.0185\n",
      "Epoch 38/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0512\n",
      "Epoch 00038: val_loss improved from 0.01845 to 0.01766, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 864ms/step - loss: 0.0512 - val_loss: 0.0177\n",
      "Epoch 39/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0473\n",
      "Epoch 00039: val_loss did not improve from 0.01766\n",
      "2/2 [==============================] - 2s 886ms/step - loss: 0.0473 - val_loss: 0.0178\n",
      "Epoch 40/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0478\n",
      "Epoch 00040: val_loss did not improve from 0.01766\n",
      "2/2 [==============================] - 2s 846ms/step - loss: 0.0478 - val_loss: 0.0183\n",
      "Epoch 41/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0440\n",
      "Epoch 00041: val_loss improved from 0.01766 to 0.01723, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 868ms/step - loss: 0.0440 - val_loss: 0.0172\n",
      "Epoch 42/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0416\n",
      "Epoch 00042: val_loss improved from 0.01723 to 0.01506, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 844ms/step - loss: 0.0416 - val_loss: 0.0151\n",
      "Epoch 43/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0412\n",
      "Epoch 00043: val_loss improved from 0.01506 to 0.01345, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 845ms/step - loss: 0.0412 - val_loss: 0.0135\n",
      "Epoch 44/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0410\n",
      "Epoch 00044: val_loss improved from 0.01345 to 0.01236, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 837ms/step - loss: 0.0410 - val_loss: 0.0124\n",
      "Epoch 45/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0406\n",
      "Epoch 00045: val_loss improved from 0.01236 to 0.01213, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 888ms/step - loss: 0.0406 - val_loss: 0.0121\n",
      "Epoch 46/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0373\n",
      "Epoch 00046: val_loss did not improve from 0.01213\n",
      "2/2 [==============================] - 2s 957ms/step - loss: 0.0373 - val_loss: 0.0126\n",
      "Epoch 47/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0361\n",
      "Epoch 00047: val_loss did not improve from 0.01213\n",
      "2/2 [==============================] - 2s 843ms/step - loss: 0.0361 - val_loss: 0.0124\n",
      "Epoch 48/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0377\n",
      "Epoch 00048: val_loss improved from 0.01213 to 0.01100, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 854ms/step - loss: 0.0377 - val_loss: 0.0110\n",
      "Epoch 49/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0335\n",
      "Epoch 00049: val_loss improved from 0.01100 to 0.01019, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 864ms/step - loss: 0.0335 - val_loss: 0.0102\n",
      "Epoch 50/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0353\n",
      "Epoch 00050: val_loss improved from 0.01019 to 0.01012, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 844ms/step - loss: 0.0353 - val_loss: 0.0101\n",
      "Epoch 51/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0306\n",
      "Epoch 00051: val_loss did not improve from 0.01012\n",
      "2/2 [==============================] - 2s 908ms/step - loss: 0.0306 - val_loss: 0.0105\n",
      "Epoch 52/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312\n",
      "Epoch 00052: val_loss improved from 0.01012 to 0.00967, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0312 - val_loss: 0.0097\n",
      "Epoch 53/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0317\n",
      "Epoch 00053: val_loss improved from 0.00967 to 0.00930, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 859ms/step - loss: 0.0317 - val_loss: 0.0093\n",
      "Epoch 54/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0287\n",
      "Epoch 00054: val_loss did not improve from 0.00930\n",
      "2/2 [==============================] - 2s 952ms/step - loss: 0.0287 - val_loss: 0.0097\n",
      "Epoch 55/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0271\n",
      "Epoch 00055: val_loss did not improve from 0.00930\n",
      "2/2 [==============================] - 2s 854ms/step - loss: 0.0271 - val_loss: 0.0101\n",
      "Epoch 56/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 00056: val_loss improved from 0.00930 to 0.00839, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 851ms/step - loss: 0.0266 - val_loss: 0.0084\n",
      "Epoch 57/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0274\n",
      "Epoch 00057: val_loss improved from 0.00839 to 0.00723, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 849ms/step - loss: 0.0274 - val_loss: 0.0072\n",
      "Epoch 58/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 00058: val_loss improved from 0.00723 to 0.00641, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 847ms/step - loss: 0.0266 - val_loss: 0.0064\n",
      "Epoch 59/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0253\n",
      "Epoch 00059: val_loss improved from 0.00641 to 0.00573, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 847ms/step - loss: 0.0253 - val_loss: 0.0057\n",
      "Epoch 60/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0238\n",
      "Epoch 00060: val_loss improved from 0.00573 to 0.00547, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0238 - val_loss: 0.0055\n",
      "Epoch 61/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 00061: val_loss improved from 0.00547 to 0.00534, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 845ms/step - loss: 0.0237 - val_loss: 0.0053\n",
      "Epoch 62/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0212\n",
      "Epoch 00062: val_loss improved from 0.00534 to 0.00513, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 990ms/step - loss: 0.0212 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 00063: val_loss improved from 0.00513 to 0.00498, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 848ms/step - loss: 0.0241 - val_loss: 0.0050\n",
      "Epoch 64/64\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0219\n",
      "Epoch 00064: val_loss improved from 0.00498 to 0.00490, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "2/2 [==============================] - 2s 876ms/step - loss: 0.0219 - val_loss: 0.0049\n",
      "Training completed in time:  3.821002121766408 min\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from time import time\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
    "    verbose=1, \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "start = time()\n",
    "model.fit(\n",
    "    [x_train[0], x_train[1]], \n",
    "    y_train, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[checkpointer], \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "duration = (time() - start)/60\n",
    "print(\"Training completed in time: \", duration, \"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model \n",
    "\n",
    "Here we will review the accuracy of the model on both the training and test data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 57, 40, 365, 1)\n",
      "0 0.0 1.0872798\n",
      "1 1.0 0.08608175\n",
      "0 0.0 0.689456\n",
      "0 0.0 5.764269\n",
      "0 0.0 1.3669777\n",
      "0 0.0 1.44807\n",
      "1 1.0 0.06697221\n",
      "0 0.0 1.1745834\n",
      "0 0.0 1.1764838\n",
      "1 1.0 0.072153926\n",
      "1 1.0 0.090201944\n",
      "1 1.0 0.0875443\n",
      "1 1.0 0.06289607\n",
      "1 1.0 0.044211827\n",
      "0 0.0 1.4250283\n",
      "1 1.0 0.086301595\n",
      "0 0.0 1.5424693\n",
      "1 1.0 0.090231456\n",
      "0 0.0 8.15467\n",
      "1 1.0 0.07098756\n",
      "1 1.0 0.09667267\n",
      "1 1.0 0.052663837\n",
      "1 1.0 0.054785863\n",
      "0 0.0 1.8447478\n",
      "1 1.0 0.04301049\n",
      "0 0.0 1.3944316\n",
      "0 0.0 1.0955516\n",
      "1 1.0 0.06272768\n",
      "1 1.0 0.061319906\n",
      "0 0.0 2.3040001\n",
      "0 0.0 1.0832397\n",
      "1 1.0 0.063796826\n",
      "1 1.0 0.08047636\n",
      "1 1.0 0.063587815\n",
      "0 0.0 6.123921\n",
      "0 0.0 6.2126627\n",
      "1 1.0 0.05811749\n",
      "0 0.0 0.9400404\n",
      "1 1.0 0.05757321\n",
      "0 0.0 1.3812172\n",
      "0 0.0 7.6590877\n",
      "1 1.0 0.06554505\n",
      "0 0.0 1.6887981\n",
      "1 1.0 0.067737326\n",
      "1 1.0 0.059289437\n",
      "0 0.0 7.082174\n",
      "1 1.0 0.10153466\n",
      "0 0.0 1.0210713\n",
      "0 0.0 1.325704\n",
      "0 0.0 1.594081\n",
      "1 1.0 0.119093716\n",
      "1 1.0 0.1112123\n",
      "0 0.0 1.1813018\n",
      "1 1.0 0.109268576\n",
      "0 0.0 1.3959684\n",
      "0 0.0 1.2058371\n",
      "1 1.0 0.10000919\n",
      "acc = 100.0%\n"
     ]
    }
   ],
   "source": [
    "predict(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 15, 40, 365, 1)\n",
      "1 1.0 0.107383825\n",
      "1 1.0 0.069897026\n",
      "0 0.0 0.99296767\n",
      "1 1.0 0.10461344\n",
      "0 0.0 7.5714693\n",
      "0 0.0 0.56158644\n",
      "0 0.0 0.8223759\n",
      "1 1.0 0.06732982\n",
      "0 0.0 0.8940802\n",
      "0 0.0 14.450246\n",
      "1 1.0 0.06707755\n",
      "1 1.0 0.10241078\n",
      "0 0.0 5.596364\n",
      "0 0.0 1.5377754\n",
      "1 1.0 0.07242619\n",
      "acc = 100.0%\n"
     ]
    }
   ],
   "source": [
    "predict(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
